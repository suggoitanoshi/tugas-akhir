\chapter{Studi Literatur}
Pada bab ini, akan dikaji literatur yang terkait \emph{Deep Learning} Terdistribusi. Pokok bahasan utama dalam bab ini adalah teori yang mendasari \emph{Deep Learning}, yang merujuk kepada \textcite{JiangDistributed}, \textcite{Choi2019}, \textcite{Fan2019}, serta \textcite{LeCun2015}. Kemudian, akan dibahas pula implementasi \emph{Deep Learrning} Terdistribusi yang ada saat ini.

\section{Machine Learning}
Berdasarkan literatur \textcite{Fan2019} serta \textcite{bishop2006pattern}, teknik \emph{Supervised Machine Learning} modern mencari suatu fungsi dengan mempelajari himpunan \emph{training data} $\{(x_i, y_i)\}_{1 \le i \le n}$, dimana $x_i \in \mathbb{R}^d$ disebut sebagai fitur,  $y_i \in \mathbb{R}$ disebut sebagai label, dan $n$ merupakan jumlah \emph{training data} yang akan dipelajari. Dari \emph{training data} tersebut, akan dicari fungsi $f: \mathbb{R}^d \mapsto \mathbb{R}$ dari kelas fungsi $\mathcal{F}$ yang dapat memprediksi \emph{output} $y_i$ berdasarkan \emph{input} $x_i$ dengan baik.

Terdapat beragam kelas fungsi \(\mathcal{F}\) yang dapat dipilih untuk mempelajari himpunan \emph{training data}. Contoh teknik terkait adalah regresi linear yang menggunakan kelas fungsi linear untuk mempelajari \emph{training data}. Selain itu, terdapat pula teknik \emph{deep learning} yang menggunakan kelas komposisi fungsi \parencite{LeCun2015}
\begin{equation}
  \{
  f(x;\theta) = W_L\sigma_L(W_{L-1} \cdots \sigma_2(W_2\sigma_1(W_1 x)))\ \vert \ \theta = \{W_1,\dots,W_L\}
  \}
\end{equation}
dimana $L$ menyatakan jumlah \emph{layer} yang umumnya disebut sebagai kedalaman sebuah model, $W_i$ merupakan bobot untuk keluaran fungsi ke-$i$, dan fungsi $\sigma_i$ merupakan fungsi aktivasi ke-$i$.

\section{Deep Learning}
Istilah \emph{deep learning} atau \emph{deep neural network} digunakan secara umum untuk menggambarkan sebuah model \emph{neural network} yang memiliki satu atau lebih \emph{hidden layer} \parencite{Fan2019,LeCun2015}. Struktur model \emph{neural network} dapat mengandung sebuah \emph{input layer}, beberapa \emph{hidden layer}, dan sebuah \emph{output layer}.

Menurut \textcite{Bengio2021}, struktur model yang memiliki beberapa lapisan fungsi memungkinkan model untuk mempelajari data yang tidak linear. Selain itu, model yang lebih dalam memungkinkan adanya transformasi fitur menjadi lebih abstrak dalam komposisi fungsi, yang kemudian dapat digunakan oleh \emph{layer} Selanjutnya.

\subsection{Model Deep Neural Network}
Model \emph{deep neural network} merupakan komposisi dari beberapa fungsi aktivasi nonlinear $\sigma$. Untuk layer ke-$l$, \emph{output} yang dihasilkan adalah

\begin{equation}
  h^{(l)} = g^{(l)}(h^{(l-1)}) = \sigma(W^{(l)}h^{(l-1)} + b^{(l)}),
\end{equation}

dengan $l \in \{1,2,\dots,L\}$, $h^{(0)} = x$, $W^{(l)}$ adalah matriks bobot, dan $b^{(l)}$ adalah matriks bias untuk \emph{layer} ke-$l$.

Beberapa fungsi yang umumnya digunakan sebagai fungsi aktivasi $\sigma$ adalah \emph{Rectified Linear Unit} (ReLU), \emph{sigmoid}, dan tanh. Selain itu, untuk \emph{output} multilabel atau lebih dari dua label, digunakan fungsi softmax pada \emph{output layer} untuk menghitung probabilitas dari fungsi linear. Definisi fungsi softmax adalah sebagai berikut:
\begin{equation}
  softmax(z_k) \triangleq \frac{\exp(z_k)}{\Sigma_k \exp(z_k)},
  k \in \{1,\dots,K\}
\end{equation}
dengan $K$ adalah kategori klasifikasi yang mungkin.

Hasil dari \emph{Deep Learning} adalah sebuah fungsi penebak $\hat{f}$. Kinerja sebuah fungsi penebak $\hat{f}$ dapat dievaluasi menggunakan galat prediksi $\mathbb{P}(y \neq \hat{f}(x))$.

\subsection{Algoritma Backpropagation}
Pembelajaran yang dilakukan di dalam \emph{deep learning} adalah meminimasi fungsi objektif yang didefinisikan. Definisi fungsi objektif dapat dibuat dengan membandingkan hasil dari \emph{output layer} $h^{(L)}$ dengan label sebenarnya $y$. Fungsi objektif yang umum digunakan untuk masalah klasifikasi adalah \emph{multinomial logistic loss} yang didefinisikan sebagai
\begin{equation}
  \mathcal{L}(f(x;\theta),y) = -\sum_{k=1}^K 1\{y=k\} \log p_k,
\end{equation}
dimana $x$ adalah input, $y$ adalah label seharusnya, $K$ adalah jumlah kelas yang digunakan, $p_k$ adalah keluaran kemungkinan input $x$ berada dalam kelas $k$ menurut fungsi $f$.

Gradient descent merupakan cara untuk meminimasi fungsi objektif $J(\theta)$ yang diparameterisasi oleh parameter model $\theta \in \mathbb{R}^d$. Algoritma ini memperbarui parameter ke arah berlawanan dari arah gradien fungsi objektif $\nabla_\theta J(\theta)$ terhadap parameternya.

Karena \emph{deep neural network} memiliki beberapa \emph{hidden layer}, maka diperlukan aturan rantai untuk menghitung gradien. Perhitungan gradien dilakukan dari \emph{output layer} dan dipropagasi balik ke \emph{layer} sebelumnya. Nilai gradien untuk \emph{layer} ke-$l-1$ dapat dihitung sebagai berikut:
\begin{equation}
  \frac{\partial J}{\partial h^{(l-1)}}
  = \frac{\partial h^{(l)}}{\partial h^{(l-1)}}
  \frac{\partial J}{\partial h^{(l)}}
  = \frac{\partial \sigma(W^{(l)} h^{(l-1)} + b^{(l)})}{\partial h^{(l-1)}}
  \frac{\partial J}{\partial h^{(l)}}
\end{equation}

Gradien tersebut kemudian dapat digunakan untuk memperbarui matriks bobot:
\begin{equation}
  W^{(l)} \leftarrow W^{(l)}
  - \eta \frac{\partial J}{\partial W^{(l)}}
  \text{, dimana }
  \frac{\partial f}{\partial W^{(l)ij}}
  = \frac{\partial f}{\partial h_i^{(l)}}\sigma'h_j^{(l-1)}
\end{equation}
Nilai $\eta > 0$ disebut sebagai \emph{learning rate}, yang mengatur seberapa jauh setiap parameter diubah dalam satu langkah pembaruan.

Nilai $\eta$ beserta jumlah parameter dalam $\theta$ dapat dikategorikan sebagai \emph{hyperparameter} yang dapat diatur untuk menentukan model \emph{deep neural network} yang dibangun. Dalam beberapa literatur, nilai \emph{learning rate} umumnya dituliskan sebagai $\alpha$.

\subsection{Optimasi Untuk Gradient Descent}
Terdapat beberapa varian dari gradient descent untuk menghitung gradien, yang dikarakterisasi oleh jumlah data yang digunakan. Varian pertama memperbarui parameter untuk setiap keseluruhan \emph{training data}, disebut sebagai \emph{batch gradient descent}. Kemudian, varian kedua menggunakan hanya satu data untuk memperbarui parameter, yang disebut sebagai \emph{stochastic gradient descent}(SGD). Varian ketiga menggunakan sebagian \emph{training data} untuk memperbarui parameter, sehingga disebut \emph{mini-batch gradient descent}. Ketiga varian tersebut memberikan pertukaran antara kecepatan pembaruan dan akurasi pembaruan.

Algoritma optimasi (selanjutnya disebut pengoptimasi) untuk gradient descent dirancang untuk mencoba menyelesaikan tantangan-tantangan yang ada pada gradient descent. Selain itu, pengoptimasi yang dirancang juga dapat mempercepat konvergensi model \emph{deep neural network} pada saat pembelajaran. Oleh karena itu, penting untuk memilih pengoptimasi yang tepat untuk pembelajaran sebuah model \emph{deep neural network}.

Terdapat beberapa pengoptimasi yang dapat digunakan dalam pelatihan model \emph{deep neural network}. Beberapa pengoptimasi yang disebutkan oleh \textcite{Ruder2016} diantaranya adalah Momentum dari \textcite{qian1999momentum}, RMSProp dari \textcite{hinton2012neural}, Adam dari \textcite{ADAMKingma}, serta pengoptimasi lainnya. Perbandingan empiris antar pengoptimasi telah dilakukan oleh banyak penulis sebelumnya. Menurut \textcite{Choi2019}, pengoptimasi yang lebih umum tidak akan memiliki kinerja yang lebih buruk dibandingkan pengoptimasi yang lebih khusus. Hasil perbandingan yang dilakukan \textcite{benchmark2021schmidt} menyatakan Adam merupakan salah satu pilihan yang cukup baik untuk banyak permasalahan, dengan alternatif lain yakni \emph{Nesterov Accelerated Gradient}(NAG) dan RMSProp.

\subsection{Pengoptimasi RMSProp}
Pengoptimasi RMSProp dituliskan oleh \textcite{hinton2012neural} untuk mendemonstrasikan momentum per parameter dalam pengoptimasi SGD. Dalam tulisan tersebut, ditawarkan sebuah cara untuk memberikan \emph{learning rate} yang berbeda untuk setiap parameter. Salah satu cara yang ditulis untuk menentukan \emph{learning rate} masing-masing parameter adalah menggunakan \emph{local gain} $g(t)$ yang diinisialisasi menjadi 1 untuk setiap parameter. Kemudian, \emph{local gain} akan diperbarui dengan aturan berikut.
\begin{equation*}
  g(t) =
  \begin{cases}
    g(t-1) + 0.5      & \text{, jika } \left(
    \frac{\partial J}{\partial w}(t) \frac{\partial J}{\partial w}(t-1) > 0
    \right)                                   \\
    g(t-1) \cdot 0.95 & \text{, lainnya}
  \end{cases}
\end{equation*}
Namun, aturan tersebut kurang baik untuk \emph{mini-batch gradient descent}, sehingga perlu adanya sebuah bilangan pembagi yang mendekati gradien \emph{mini-batch} yang berdekatan. Oleh karena itu, digunakan sebuah rerata bergerak dari kuadrat gradien setiap parameter.
$$
  MeanSquare(w, t) = 0.9 MeanSquare(w, t-1) + 0.1\left(\frac{\partial J}{\partial w}(t)\right)^2
$$

\subsection{Pengoptimasi Adam}
\begin{algorithm}
  \setstretch{1}
  \caption{Algoritma Pengoptimasi Adam}\label{Adam}
  \begin{algorithmic}[1]
    \Function{Adam}{$\alpha$, $\beta_1$, $\beta_2$, $\theta_0$}
    \State $m_0 \gets 0$ \Comment{Inisialisasi estimasi momen pertama}
    \State $v_0 \gets 0$ \Comment{Inisialisasi estimasi momen kedua}
    \State $t \gets 0$ \Comment{Inisialisasi \emph{timestep}}
    \While{$\theta_t$ not converged}
    \State $t \gets t+1$
    \State $g_t \gets \nabla_\theta f_t (\theta_{t-1})$
    \State $m_t \gets \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t$ \Comment{Perbarui estimasi momen pertama terbias}
    \State $v_t \gets \beta_2 \cdot v_{t-1} + (1-\beta_2) \cdot g_t^2$ \Comment{Perbarui estimasi momen kedua terbias}
    \State $\hat{m_t} \gets m_t/(1-\beta_1^t)$ \Comment{Hitung estimasi momen pertama dengan perbaikan bias}
    \State $\hat{v_t} \gets v_t/(1-\beta_2^t)$ \Comment{Hitung estimasi momen kedua dengan perbaikan bias}
    \State $\theta_t \gets \theta_{t-1} - \alpha \cdot \hat{m_t}/\sqrt{\hat{v_t}}+\epsilon$
    \EndWhile
    \State \textbf{return} $\theta_t$ \Comment{Parameter hasil optimasi}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

Tulisan dari \textcite{ADAMKingma} menjelaskan sebuah algoritma untuk mengoptimasi SGD menggunakan hanya gradien orde pertama. Pengoptimasi tersebut menghitung \emph{learning rate} adaptif untuk setiap parameter menggunakan estimasi momen orde pertama dan kedua dari gradiennya. Penggunaan momen dapat membantu pengoptimasi agar tidak terjebak pada minimum lokal.

Algoritma yang dijelaskan dalam literatur tersebut menggunakan estimasi momen pertama dan kedua, yakni $m_t$ dan $v_t$. Parameter $\beta_1$ dan $\beta_2$ sebagai laju peluruhan untuk estimasi momen. Keduanya menjadi \emph{hyperparatemer} yang dapat diatur, bersama dengan \emph{hyperparameter} lain dari SGD. Literatur tersebut memberikan nilai-nilai dasar yang cukup baik untuk \emph{hyperparameter} yang ada, yakni $\beta_1 = 0.9$, $\beta_2 = 0.999$, $\alpha = 0.001$. Selain itu, nilai $\epsilon$ yang digunakan adalah $\epsilon = 10^{-8}$

Hasil analisis dari \textcite{ADAMKingma} menunjukkan \emph{stepsize} yang digunakan akan mendekati nol apabila fungsi objektif mendekati optimum. Selain itu, terdapat perbaikan bias untuk momen pertama dan kedua agar tidak terbias menuju nol.

\section{Distributed Deep Learning}
Pembelajaran dalam \emph{deep learning} membutuhkan komputasi yang banyak, terutama ketika jumlah parameter yang harus dioptimasi mencapai lebih dari jutaan. Oleh karena itu, pembelajaran \emph{deep neural network} kemudian dilakukan secara terdistribusi untuk mempercepat proses. Namun, terdapat beberapa masalah mendasar untuk membuat pembelajaran \emph{deep neural network} dapat dilakukan secara terdistribusi. Pertama, bagaimana komputasi akan diparalelisasi. Kedua, bagaimana mengagregasi parameter dari hasil pembelajaran. Ketiga, bagaimana mensinkronisasi \emph{worker} yang menjalankan \emph{deep learning}. Keempat, bagaimana mengoptimasi komunikasi selama pembelajaran.

\subsection{Optimasi komunikasi}
Untuk membagi parameter ke \emph{worker} yang terdistribusi, beberapa \emph{parameter server} dapat digunakan. Sebuah \emph{parameter server} bertugas membagikan parameter dan mengagregasi kembali parameter baru yang dihitung oleh \emph{worker}. Penggunaan beberapa \emph{parameter server} dapat meringankan beban setiap \emph{parameter server}. Dalam skema ini, setiap parameter baru harus dikirimkan ke \emph{parameter server} sehingga semua model dapat mengetahui parameter terbaru. Hal tersebut penting untuk konvergensi \emph{deep neural network}.

Skema kompresi pada parameter dapat digunakan untuk mengoptimasi komunikasi lebih jauh. Beberapa kompresi yang umum dilakukan adalah kompresi \emph{lossless} untuk bilangan bulat (\emph{integer}) dan matriks jarang (\emph{sparse matrices}). Kemudian, terdapat pula kompresi \emph{lossy} untuk bilangan real yang dinyatakan dalam bentuk \emph{floating point}. Algoritma kompresi seperti yang dikembangkan \textcite{Jin2021Comet} dan \textcite{Horvoth2022Natural} dapat melakukan kompresi \emph{lossy} untuk mengoptimasi komunikasi dan penggunaan memori saat pembelajaran.

\subsection{Pengoptimasi pada Deep Learning Terdistribusi}
Pengoptimasi yang disebutkan sebelumnya dikembangkan untuk digunakan pada lingkungan yang terpusat. Oleh karenanya, terdapat penelitian lebih lanjut untuk meninjau pengoptimasi yang ada ketika digunakan dalam lingkungan terdistribusi. Salah satu pengoptimasi yang sebelumnya telah disebutkan sebagai alternatif yang cukup baik adalah pengoptimasi Adam. Terdapat banyak pengembangan untuk mengoptimasi Adam di lingkungan terdistribusi, umumnya dengan melakukan kompresi seperti dilakukan oleh \textcite{Chen2021CADA}. Selain itu, terdapat pula algoritma yang mengurangi jumlah komunikasi yang diperlukan, seperti ditulis oleh \textcite{Li2022Federated} dan \textcite{Chen2021CADA}.

\section{Penelitian Terkait}

\subsection{Pengurangan Komunikasi}
Komunikasi antar \emph{worker} menjadi sebuah pembatas kecepatan pembelajaran. Pengurangan jumlah sinkronisasi dapat mempercepat proses pembelajaran, namun perlu ditinjau terlebih dahulu efeknya terhadap konvergensi model. Penelitian \textcite{Chen2018LAG} memberikan alternatif solusi, yakni \emph{lazily aggregated gradient} untuk mengurangi komunikasi. Teknik yang digunakan adalah dengan memilih \emph{worker} yang perlu mengirimkan gradien melalui kriteria tertentu. Kriteria yang diberikan dievaluasi pada setiap \emph{worker}, namun apabila \emph{broadcast} dianggap berat maka kriteria dapat dievaluasi pada \emph{parameter server}.

Pengurangan yang diberikan oleh \textcite{Chen2018LAG} dapat mempercepat proses pembelajaran. Akan tetapi, \textcite{Chen2021CADA} meninjau bahwa keefektifan dari algoritma tersebut akan berkurang seiring berjalannya pembelajaran. penelitian \textcite{Chen2021CADA} memberikan alternatif lain untuk mengurangi jumlah komunikasi yang diperlukan. Algoritma tersebut, yang diberi tajuk \emph{CADA}, memiliki kriteria yang berbeda dari \emph{lazily aggregated gradient}, dan telah ditunjukkan akan konvergen pada kondisi yang sesuai.

Dalam CADA, pembaruan parameter dilakukan dengan mengambil gradien baru hanya dari sebagian \emph{worker}, sedangkan \emph{worker} lainnya akan menggunakan gradien sebelumnya. Terdapat dua varian CADA dengan kondisi yang berbeda. Kedua varian kondisi dapat dilihat pada \autoref{CADA1} dan \autoref{CADA2}. Dalam kedua kondisi, \emph{worker} akan mengirimkan gradien apabila \autoref{CADA1} atau \autoref{CADA2} tidak terpenuhi. Kondisi tersebut dievaluasi pada setiap \emph{worker} untuk setiap \emph{iterasi}.

\begin{equation}
  \label{CADA1}
  \|\tilde{\delta}_t^{(i)} - \tilde{\delta}^{(i)}_{\tau_t^{(i)}}\|^2 \leq \frac{c}{d_{max}} \sum_{d=1}^{d_{max}} \|\theta_{t+1-d} - \theta_{t-d}\|^2
\end{equation}
\begin{equation}
  \label{CADA2}
  \|\nabla f(\theta_t;\xi^{(i)_t}) - \nabla f(\theta_{t-\tau}^{(i)};\xi_t^{(i)})\|^2 \leq \frac{c}{d_{max}} \sum_{d=1}^{d_{max}} \|\theta_{t+1-d} - \theta_{t-d}\|^2
\end{equation}

Dalam kedua persamaan, variabel $t$ menunjukkan penghitung iterasi. Kemudian, variabel $\tau$ menunjukkan penghitung \emph{staleness} atau keterlambatan \emph{worker} tertentu. Variabel $(i)$ menunjukkan \emph{worker} yang sedang diacu, dan nilai $c$ merupakan konstanta yang dapat ditentukan untuk mengatur nilai ambang pada kedua persamaan.

Dalam \autoref{CADA1}, $\tilde{\delta}_t^{(i)} = \nabla f(\theta_t;\xi_t^{(i)}) - \nabla f(\tilde{\theta};\xi_t^{(i)})$ adalah inovasi gradien pada contoh data $\xi_t^{(i)}$, sedangkan $\tilde{\delta}_{\tau_t^{(i)}}^{(i)} = \nabla f(\theta_{t-\tau_t^{(i)}};\xi_{t-\tau_t^{(i)}}^{(i)}) - \nabla f(\tilde{\theta};\xi_{t-\tau_t^{(i)}}^{(i)})$ adalah inovasi gradien pada contoh data $\xi_{t-\tau_t^{(i)}}^{(i)}$. Nilai parameter $\delta$ merupakan nilai parameter saat ini, sedangkan nilai $\tilde{\delta}$ merupakan nilai parameter iterasi sebelumnya yang akan diperbarui setiap $D$ iterasi.

Dalam \autoref{CADA2}, nilai $\nabla f$ merupakan gradien fungsi f pada titik tertentu. Lebih lanjut, nilai $\nabla f(\theta^k;\xi^k_m)$ menggambarkan gradien fungsi pada iterasi saat ini dengan contoh data $\xi^k_m$, dan nilai $\nabla f(\theta^{k-\tau}_m;\xi^k_m)$ menggambarkan gradien fungsi pada $\tau$ iterasi sebelumnya dengan contoh data $\xi^k_m$.

\subsection{Kompresi Gradien dan Bobot}
Kompresi dapat dilakukan untuk mengoptimasi Adam pada lingkungan terdistribusi. Penelitian yang dilakukan oleh \textcite{Chen2021Quantized} memberikan sebuah alternatif kompresi yang dapat dilakukan, yakni dengan mengkuantisasi gradien dan bobot. Kuantisasi pada gradien bertujuan mengurangi jumlah bit yang digunakan. Efek samping dari kuantisasi adalah menurunnya presisi yang dapat digunakan. Oleh karena itu, penelitian \textcite{Chen2021Quantized} menawarkan \emph{error-feedback} untuk mengurangi efek bias akibat kuantisasi. Selain kuantisasi, penelitian tersebut juga menggunakan \emph{learning rate} yang adaptif seperti pada Adam dan RMSProp.

Penelitian selanjutnya yang dilakukan oleh \textcite{Chen2022Efficient} memberikan algoritma yang diberi tajuk \emph{Efficient-Adam}. Algoritma Efficient-Adam menggunakan pemetaan kuantisasi dua arah untuk mengurangi beban komunikasi. Pemetaan kuantisasi digunakan hanya pada pengiriman pembaruan parameter dari dan ke \emph{parameter server}. Sebelum \emph{worker} mengirimkan pembaruan parameter, nilai tersebut akan dikuantisasi. Kemudian, \emph{parameter server} akan menerima pembaruan parameter, merata-ratakannya, lalu kembali melakukan kuantisasi terhadap pembaruan yang sudah dirata-ratakan sebelum dikirimkan kepada \emph{worker}. Sama seperti pada \textcite{Chen2021Quantized}, Algoritma Efficient-Adam juga menggunakan \emph{error-feedback} untuk mengurangi efek bias dari kuantisasi.

Pemetaan kuantisasi yang dipilih dalam Efficient-Adam adalah pemetaan yang memenuhi \autoref{efficientquant}. Kemudian, Efficient-Adam menggunakan dua buah pemetaan kuantisasi yang mungkin berbeda antara \emph{worker} dengan \emph{parameter server}. Algoritma yang digunakan Efficient-Adam dapat dilihat pada \autoref{efficientps} untuk bagian \emph{parameter server} dan \autoref{efficientwk} untuk bagian \emph{worker}. Bagian \emph{error-feedback} dapat dilihat sebagai pembaruan parameter yang tertunda. Bagian \emph{error-feedback} dapat dilihat pada \autoref{efficientps} baris 7 dan pada \autoref{efficientwk} baris 9.

\begin{definition}
  \label{efficientquant}
  Pemetaan $\mathcal{Q}: \mathbb{X} \to \mathbb{X}$ merupakan pemetaan kuantisasi jika terdapat dua konstanta $\delta > 0$ dan $\delta' \geq 0$ sehingga kedua pertaksamaan berikut terpenuhi: $\|x-\mathcal{Q}(x)\| \leq (1-\delta)\|x\| + \delta'$ dan $\|\mathcal{Q}(x)\| \leq (2-\delta)\|x\|$
\end{definition}

\begin{algorithm}[H]
  \setstretch{1}
  \caption{Efficient-Adam untuk Parameter Server}\label{efficientps}
  \begin{algorithmic}[1]
    \State \textbf{Parameter:} Fungsi Kuantisasi $\mathcal{Q}_s$ yang memenuhi \autoref{efficientquant}
    \State \textbf{Inisialisasi} vektor parameter $\theta_0$, error term $e_1 \gets 0$
    \State Sebarkan $\theta_0$ ke semua \textit{worker}
    \For{$t = 1,2,\dots,T$}
    \State $\hat{\delta_t} \gets \textnormal{rata-rata } \delta_t^{(i)}$ dari setiap \textit{worker}
    \State Sebarkan $\tilde{\delta_t} \gets \mathcal{Q}(\hat{\delta_t} + e_t)$
    \State $e_{t+1} \gets e_{t}$
    \State $\theta_{t+1} \gets \theta_t - \tilde{\delta_t}$
    \EndFor
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \setstretch{1}
  \caption{Efficient-Adam untuk Worker}\label{efficientwk}
  \begin{algorithmic}[1]
    \State \textbf{Parameter:} Fungsi Kuantisasi $\mathcal{Q}_s$ yang memenuhi \autoref{efficientquant}, hyperparameter $\alpha_t, \beta_1, \beta_2$
    \State \textbf{Inisialisasi} vektor parameter $\theta_0$, error term $e_1 \gets 0$, $m_0 \gets 0$, $v_0 \gets \epsilon$
    \State Terima $\theta_0$ dari \emph{parameter server}
    \For{$t = 1,2,\dots,T$}
    \State $g_t^{(i)} \gets f(\xi_k)$
    \State $v_t^{(i)} \gets \theta_t v_{t-1}^{(i)} + (1-\theta_t)[g_t^{(i)}]^2$
    \State $m_t^{(i)} \gets \beta_1 m_{t-1}^{(i)} + (1 - \beta_1)g_t^{(i)}$
    \State Kirim $\delta_t^{(i)} = \mathcal{Q}_w(\alpha_t m_t^{(i)} / \sqrt{v_t^{(i)}} + e_t^{(i)})$ ke \emph{parameter server}
    \State $e_{t+1}^{(i)} = \alpha_t \frac{m_t^{(i)}}{\sqrt{v_t^{(i)}}} + e_t^{(i)} - \delta_t^{(i)}$
    \State Menerima $\tilde{\delta}_t$ dari \emph{parameter server}
    \State $\theta_{t+1} \gets \theta_t - \tilde{\delta}_t$
    \EndFor
  \end{algorithmic}
\end{algorithm}
